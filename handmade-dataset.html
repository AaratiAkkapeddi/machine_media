<!DOCTYPE html>
<html lang="en">
<head>
    <link rel="stylesheet" href="styles.css">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Machine Media</title>
</head>
<body>
    <nav>
        <div id="nav-trigger">
            <svg width="68" height="62" viewBox="0 0 68 62" fill="none" xmlns="http://www.w3.org/2000/svg">
                <path d="M2.70455 27.7954H68L65.4886 33.5909H0L2.70455 27.7954Z" fill="white"/>
                <path d="M2.70455 0H68L65.4886 5.79545H0L2.70455 0Z" fill="white"/>
                <path d="M2.70455 55.5908H68L65.4886 61.3863H0L2.70455 55.5908Z" fill="white"/>
                </svg>
                
        </div>
        <ul>
            <li><a href="./">Home</a></li>
            <li><a href="./slide-decks.html">Slide decks</a></li>
            <li><a href="./handmade-dataset.html">Handmade Dataset</a></li>
            <li><a href="./mini-project/make-a-meme.html">Make a meme</a></li>
            <li><a href="./build-a-text-generator.html">Build a Text Generator</a></li>
            <li><a href="./mini-project/teachable-machine.html">Teachable Machine</a></li>
            <li><a href="./mini-project/research-a-dataset.html">Research A Dataset</a></li>
            <li><a href="./cv_dazzle/index.html">C.V. Dazzle </a></li>
            <li><a href="./mini-project/disinformation-campaign.html">Disinformation Campaign </a></li>
            <li><a href="./mini-project/seeing-networks-walk.html">Seeing Networks Walk </a></li>
            <li><a href="./mini-project/alt-text.html">Alt-text Exploration  </a></li>
            <li><a href="./resources.html">Resources</a></li>
        </ul>
    </nav>
    <main>
       <h1>Handmade Dataset</h1>
       <em>Final Project</em>
    <p><h4>Description</h4>
        You and your team will create a training dataset of images together throughout the rest of the semester. At the end of the semester, we will train a Generative Adversarial Network on your dataset. <em>You will not be assessed on the results of the GAN, but rather the thoughtfulness, care, and consideration of your dataset creation process.</em> You will need to have <em>at least 800 images</em> within your dataset so please take that into consideration when developing your project idea. **The more homogenous your images are, the "better" your GAN will work. The more diverse your images are, the more images you will need to get an output that resembles the input images. Because of this, I am limiting your subject matter/ideas to that which can fit within our "photo station" and be photographed/filmed on a consistant black or white background. So your subject matter should be able to fit on a table top space of 15" x 15." 
        <h4>Technical Specifications:</h4> 
        <ul>
            <li>**Your subject matter should be able to fit on a table top space of 15" x 15."  </li>
            <li>Example of Sarah Meyohas rose petal dataset:
                <img src="./petal.png"/>
            </li>
            <li>Each image will end up being square. I can automatically crop images for you but because of this, you will want to center your subject matter in the middle of the frame.</li>
            <li>You don't need to label your images with categories or descriptions. We will be using <a href='https://github.com/NVlabs/stylegan'>StyleGAN</a> which just takes a dataset of images and generates images based on the training data.</li>
            <li>You will upload your dataset to a google drive folder that I will create for your group.</li>
            <li>You will need at least 800 images (see below for tips)</li>
           
            
        </ul>
        <h4>Tips:</h4>
        <ul>
            
            <li>You can also use video stills. This is a great way to generate thousands of images easily without taking individual photos. I have a script for automating the process of splitting video into image frames and can do this for you.</li>
            <li> Depending on your subject matter, you can also photograph your objects in a variety of positions. For example, one photograph of a coin can become four photographs if I turn it and flip it in a different way for each image.</li>
            <li>Upload as you go. Don't wait until the last minute to transfer your images to the google drive (you don't want a situation where your external harddrive breaks, or your camera/phone is lost and you lose all your work!)</li>
            <li>The more homogenous your images are, the "better" your GAN will work. The more diverse your images are, the more images you will need to get an output that resembles the input images.</li>
            <li>In regards to the above point, you can edit your images to <em>create</em> homogeneity. For example, I have done this with a dataset of faces where I used facial recognition to align the images so that the eyes are in the same position across the images. Reach out to me if you have alignment questions and I will be able to tell you whether alignment can be automated or needs to be manually done.</li>
        </ul>
        <h4>Submission schedule:</h4> 
        <ul>
            <li><a href="https://docs.google.com/presentation/d/1ElGhkXYaWmjQ3JAN8Cm5IpRgPyLOdf0eRpiSEuoCxuY/edit?usp=sharing">5-minute concept presentation</a> due <strong>Week 6, October 11th</strong></li>
            <li><a href="https://docs.google.com/document/d/1cQxokLLwKERp4VOQ0tF76tuqGCpTNNRcLAnr7RkFlJ0/edit?usp=sharing">Datasheet</a> due <strong>Week 7, October 18th</strong></li>
            <li>at least 50% of Dataset due <strong>Week 10, Nov 8th</strong></li>
            <li>Your dataset needs to be done by <strong>Week 14, December 12th</strong></li>
            <li><a href="https://docs.google.com/presentation/d/1ktDJ2quv1p-Yr8x8VmSuMG5GGBLg9dPL_vojXbmBhAI/edit?usp=sharing">Final Presentations</a> <strong>Week 15, December 19th</strong></li>
    
        </ul>
        <h4>Photo Station Sign-up sheet: <a href="https://docs.google.com/spreadsheets/d/1ic-FVmslw7aJ3tBuY_hQ0eotTZdxIVNX7Z_ycPnNImg/edit?usp=sharing">link</a></h4>
        <h4>Inspo:</h4>
       <ul>
        <li><a href="https://sarahmeyohas.com/cloud-of-petals/">Sarah Meyohas - Roses at Bell</a></li>
        <li><a href="http://annaridler.com/myriad-tulips">Anna Ridler - Myriad Tulips</a></li>
        <li><a href="http://annaridler.com/cypress-trees-2021">Anna Ridler - Cypress Trees</a></li>
        <li><a href="https://www.stephaniedinkins.com/ntoo.html">Stephanie Dinkins - Ntoo</a></li>
        <li><a href="https://floriandombois.net/works/seismic-stations.html">Florian Dombois - Seismic Stations</a></li>
        <li><a href="https://tarynsimon.com/works/image_atlas/#1">Taryn Simon - Image Atlas</a></li>
        <li><a href="https://www.nora-al-badri.de/works-index#babylonian-vision">Nora al Badri - Babylonian Vision</a></li>
        <li><a href="https://tarynsimon.com/works/contraband/#1">Taryn Simon - Contraband</a></li>
        <li><a href="https://www.printedmatter.org/catalog/63022/">Maryam Jafri - Independence Day</a></li>
        <li><a href="http://salavon.com/work/smith-jones-checkerboard/">Jason Salavon - Smith Jones Checkerboard</a></li>
        <li><a href="https://imgoogle.dinakelberman.com/">Dina Kelberman - Imgoogle</a></li>
        <li><a href="https://neuralzoo.com/">Sofia Crespo - Neural Zoo</a></li>
       </ul>   <p>

   </p>
    </main>
    <script src="./main.js"></script>

    
</body>
</html>